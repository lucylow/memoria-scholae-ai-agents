{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 id,title,year,doi,mem_id,abstract\
paper:AUR-1905,"On the Dynamics of Scholarly Knowledge Graphs",1905,10.0000/aur.1905,mem:AUR-1905,"Explores early principles of academic knowledge organization and citation scaffolding."\
paper:ALG-1950,"Foundations of Algorithmic Logic",1950,10.0000/alg.1950,mem:ALG-1950,"Establishes algorithmic frameworks foundational to computational logic and symbolic reasoning."\
paper:DL-1986,"Deep Learning Emergence",1986,10.0000/dl.1986,mem:DL-1986,"Historical perspective on the evolution of neural networks and perceptron limitations."\
paper:GNN-2017,"Graph Neural Networks: Foundations",2017,10.0000/gnn.2017,mem:GNN-2017,"Survey and theoretical framework connecting topology and representation learning."\
paper:AI-2023,"AI in Scholarly Discovery",2023,10.0000/ai.2023,mem:AI-2023,"Presents Memoria Scholae: a system synthesizing persistent memory with multi-agent graph reasoning."\
paper:TR-2022,"Transformer Architectures and Applications",2022,10.0000/tr.2022,mem:TR-2022,"Review of transformer models and attention mechanisms across domains."\
paper:PF-2020,"Protein Structure Prediction with ML",2020,10.0000/pf.2020,mem:PF-2020,"Machine learning approaches to protein folding and structural prediction."\
}